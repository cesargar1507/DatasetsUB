{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "collapsed_sections": [
        "KOl-ubvXXMH1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cesargar1507/DatasetsUB/blob/main/Copy_of_TFM_MOD(RevisadoF2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXvNrUprHSkt",
        "outputId": "bb1ad6b3-bafb-4678-ebc2-6d9cbea71cce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘listenv’, ‘parallelly’, ‘future’, ‘globals’, ‘shape’, ‘future.apply’, ‘numDeriv’, ‘progressr’, ‘SQUAREM’, ‘diagram’, ‘lava’, ‘prodlim’, ‘proxy’, ‘iterators’, ‘clock’, ‘gower’, ‘hardhat’, ‘ipred’, ‘timeDate’, ‘e1071’, ‘foreach’, ‘ModelMetrics’, ‘plyr’, ‘pROC’, ‘recipes’, ‘reshape2’\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "library(dplyr)\n",
        "library(readr)\n",
        "install.packages(\"caret\")\n",
        "library(caret)\n",
        "install.packages(\"ggplot2\")\n",
        "library(ggplot2)\n",
        "install.packages(\"randomForest\")\n",
        "library(randomForest)\n",
        "library(lubridate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Instalar y cargar las bibliotecas necesarias\n",
        "install.packages(\"googledrive\")\n",
        "library(googledrive)"
      ],
      "metadata": {
        "id": "CDiBiGVgNH5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Autenticarse con Google Drive\n",
        "drive_auth()"
      ],
      "metadata": {
        "id": "VlTTd6glNKsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3daca8-a1e3-4009-c6b4-a947b19a13df"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[22mIs it OK to cache OAuth access credentials in the folder \u001b[34m~/.cache/gargle\u001b[39m\n",
            "between R sessions?\n",
            "\u001b[1m1\u001b[22m: Yes\n",
            "\u001b[1m2\u001b[22m: No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Especificar el ID del archivo y la ruta de destino\n",
        "file_id <- \"https://drive.google.com/file/d/1c8ATZ5VxKEo1hCmjyALNGkxGY_KmI-xx/view?usp=drivesdk\"  # Reemplaza este ID con el ID de tu archivo\n",
        "drive_download(as_id(file_id), path = \"archivo.csv\", overwrite = TRUE)"
      ],
      "metadata": {
        "id": "zpilSoL7NNH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leer el archivo CSV desde la URL\n",
        "urlAge <- \"https://raw.githubusercontent.com/cesargar1507/DatasetsUB/main/machine_age.csv\"\n",
        "urlMechanic <- \"https://raw.githubusercontent.com/cesargar1507/DatasetsUB/main/mechanic_antiquity.csv\"\n",
        "df <- read_csv(\"archivo.csv\", show_col_types = FALSE)\n",
        "df_age <- read_csv(urlAge, show_col_types = FALSE)\n",
        "df_mechanic <- read_csv(urlMechanic, show_col_types = FALSE)"
      ],
      "metadata": {
        "id": "p7Ac95EBV6df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(df)"
      ],
      "metadata": {
        "id": "z2sxgjL5cMt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(df,5)"
      ],
      "metadata": {
        "id": "qzZX5SgOtE09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LIMPIEZA DE DATOS**"
      ],
      "metadata": {
        "id": "KOl-ubvXXMH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sapply(df, function(x) sum(is.na(x)))\n",
        "#Fiabilidad suficiente para continuar con el trabajo"
      ],
      "metadata": {
        "id": "ttjLXcMWRvy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover el símbolo de dólar y las comas, y convertir a float\n",
        "df$parts_cost <- as.numeric(gsub(\"[\\\\$,()]\", \"\", df$parts_cost))"
      ],
      "metadata": {
        "id": "IfrIeddmGwIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir la columna 'Date' al formato adecuado\n",
        "df$date <- as.Date(df$date, format=\"%m/%d/%Y\")  # Ajusta el formato según tus datos\n",
        "# Ordenar el DataFrame por fecha\n",
        "df <- df %>%\n",
        "  arrange(date)"
      ],
      "metadata": {
        "id": "ss5BYMi8Vtvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean(df$downtime_gross < 0)"
      ],
      "metadata": {
        "id": "bqrYJi1Ksvn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar registros donde downtimeGross no sea negativo\n",
        "df <- df %>%\n",
        "  filter(downtime_gross >= 0)"
      ],
      "metadata": {
        "id": "oOqbbJuhkqTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean(df$repair_hours < 0)"
      ],
      "metadata": {
        "id": "gofP8VjtS_l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eliminar columnas que no seran utilizadas\n",
        "df <- select(df, -problem_code, -failure_code, -cause_code, -action_code, -pit_coverage, -real_downtime, -repair_hours)\n",
        "#Se han eliminado codigos y variables calculadas"
      ],
      "metadata": {
        "id": "FZkbiV-4SiWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la diferencia en días entre fechas consecutivas\n",
        "df <- df %>%\n",
        "  group_by(equipment) %>%\n",
        "  mutate(Days_Between_Failures = difftime(date, lag(date), units = \"days\"))\n",
        "\n",
        "# Reemplazar los valores NA en Days_Between_Failures\n",
        "df$Days_Between_Failures[is.na(df$Days_Between_Failures)] <- as.numeric(difftime(df$date[is.na(df$Days_Between_Failures)], as.Date(\"2023-01-01\"), units = \"days\"))"
      ],
      "metadata": {
        "id": "82Hp91p7aia4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir 'Days_Between_Failures' a numeric\n",
        "df$Days_Between_Failures <- as.numeric(df$Days_Between_Failures, units = \"days\")"
      ],
      "metadata": {
        "id": "lkjfo3ZWc3iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cambio de nombre de mecánico cuyo nombre está escrito de dos formas\n",
        "df <- df %>%\n",
        "  mutate(mechanic = ifelse(mechanic == \"GALEAS PEREZ EDWIN ROGELIO\", \"Edwin Rogelio Galeas Perez\", mechanic))"
      ],
      "metadata": {
        "id": "x_irucm4xXiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la tabla de frecuencias de mechanic\n",
        "freq_mechanic <- table(df$mechanic)\n",
        "\n",
        "# Ordenar las frecuencias de menor a mayor\n",
        "freq_sorted_mechanic <- sort(freq_mechanic)\n",
        "\n",
        "# Calcular la frecuencia relativa acumulada\n",
        "freq_relative_mechanic <- cumsum(freq_sorted_mechanic) / sum(freq_sorted_mechanic)\n",
        "\n",
        "# Definir umbral de frecuencia acumulada\n",
        "umbral <- 0.2\n",
        "\n",
        "# Identificar categorías con frecuencia relativa acumulada menor que el umbral\n",
        "categorias_baja_frecuencia_mechanic <- names(freq_sorted_mechanic[freq_relative_mechanic < umbral])\n",
        "\n",
        "# Reemplazar categorías con baja frecuencia por \"Otros\"\n",
        "df$mechanic[df$mechanic %in% categorias_baja_frecuencia_mechanic] <- \"Otros\""
      ],
      "metadata": {
        "id": "oewAwD9Lmley"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la tabla de frecuencias de problem_desc\n",
        "freq_problem <- table(df$problem_desc)\n",
        "\n",
        "# Ordenar las frecuencias de menor a mayor\n",
        "freq_sorted_problem <- sort(freq_problem)\n",
        "\n",
        "# Calcular la frecuencia relativa acumulada\n",
        "freq_relative_problem <- cumsum(freq_sorted_problem) / sum(freq_sorted_problem)\n",
        "\n",
        "# Definir umbral de frecuencia acumulada\n",
        "umbral <- 0.2\n",
        "\n",
        "# Identificar categorías con frecuencia relativa acumulada menor que el umbral\n",
        "categorias_baja_frecuencia_problem <- names(freq_sorted_problem[freq_relative_problem < umbral])\n",
        "\n",
        "# Reemplazar categorías con baja frecuencia por \"Otros\"\n",
        "df$problem_desc[df$problem_desc %in% categorias_baja_frecuencia_problem] <- \"Otros\""
      ],
      "metadata": {
        "id": "QG3Xgj0BqI2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la tabla de frecuencias de failure_desc\n",
        "freq_failure <- table(df$failure_desc)\n",
        "\n",
        "# Ordenar las frecuencias de menor a mayor\n",
        "freq_sorted_failure <- sort(freq_failure)\n",
        "\n",
        "# Calcular la frecuencia relativa acumulada\n",
        "freq_relative_failure <- cumsum(freq_sorted_failure) / sum(freq_sorted_failure)\n",
        "\n",
        "# Definir umbral de frecuencia acumulada\n",
        "umbral <- 0.2\n",
        "\n",
        "# Identificar categorías con frecuencia relativa acumulada menor que el umbral\n",
        "categorias_baja_frecuencia_failure <- names(freq_sorted_failure[freq_relative_failure < umbral])\n",
        "\n",
        "# Reemplazar categorías con baja frecuencia por \"Otros\"\n",
        "df$failure_desc[df$failure_desc %in% categorias_baja_frecuencia_failure] <- \"Otros\""
      ],
      "metadata": {
        "id": "Hi-CQmVYqzzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convertir horas a minutos\n",
        "df$downtime_gross <-df$downtime_gross*60"
      ],
      "metadata": {
        "id": "WMurWA3vB5zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write.csv(df,\"arhivo2.csv\")"
      ],
      "metadata": {
        "id": "Oa3svj4fVTm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ANALISIS DE VARIABLES**"
      ],
      "metadata": {
        "id": "-Na-VdHFXR5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim(df)"
      ],
      "metadata": {
        "id": "ufkTTqfldMbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variable \"Operación\"**"
      ],
      "metadata": {
        "id": "btd4X3WvdR81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la frecuencia de cada operación\n",
        "operation_freq <- df %>%\n",
        "  group_by(operation) %>%\n",
        "  summarise(count = n()) %>%\n",
        "  arrange(desc(count))\n",
        "\n",
        "# Calcular la frecuencia relativa\n",
        "operation_freq <- operation_freq %>%\n",
        "  mutate(relative_freq = count / sum(count))\n",
        "\n",
        "operation_freq"
      ],
      "metadata": {
        "id": "_ceeX9_wEfXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar los datos por frecuencia descendente\n",
        "operation_freq <- operation_freq %>%\n",
        "  arrange(desc(count))\n",
        "\n",
        "options(repr.plot.width=17, repr.plot.height=10)\n",
        "\n",
        "ggplot(operation_freq, aes(y = reorder(operation, count), x = count)) +\n",
        "  geom_bar(stat = \"identity\", fill = 'skyblue') +\n",
        "  geom_text(aes(label = paste0(round(relative_freq * 100, 1), \"%\")), vjust = -0.5, hjust = 0, size = 5) +\n",
        "  labs(title = \"Frecuencia relativa de operaciones con más fallos\",\n",
        "       y = \"Operación\",\n",
        "       x = \"Frecuencia\") +\n",
        "  theme_minimal() +\n",
        "  theme(\n",
        "    axis.text.x = element_text(angle = 45, hjust = 1, size = 12), # Cambia el tamaño del texto del eje x\n",
        "    axis.text.y = element_text(size = 12),                         # Cambia el tamaño del texto del eje y\n",
        "    axis.title.x = element_text(size = 14),                        # Cambia el tamaño del título del eje x\n",
        "    axis.title.y = element_text(size = 14),                        # Cambia el tamaño del título del eje y\n",
        "    plot.title = element_text(size = 16, hjust = 0.5)              # Cambia el tamaño del título del gráfico y lo centra\n",
        "  )"
      ],
      "metadata": {
        "id": "61YaB4AqXI4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "operation_freq <- operation_freq %>%\n",
        "  mutate(failure_percentage = (count / sum(count)) * 100)"
      ],
      "metadata": {
        "id": "zf5bpvuPUYJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "operation_freq <- operation_freq %>%\n",
        "  mutate(failure_group = cut(failure_percentage,\n",
        "                             breaks = c(-Inf, 1, 2, 3, 5, Inf),\n",
        "                             labels = c(\"Menos del 1%\", \"1%-2%\", \"2%-3%\", \"3%-5%\", \"Más del 5%\")))"
      ],
      "metadata": {
        "id": "bDR_VFOKUaZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "operation_freq"
      ],
      "metadata": {
        "id": "AlijwpRCUcNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variable \"problem_desc\"**"
      ],
      "metadata": {
        "id": "P4Sxra9vdXIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la frecuencia de problemas de maquinaria\n",
        "problem_freq <- df %>%\n",
        "  group_by(problem_desc) %>%\n",
        "  summarise(count = n()) %>%\n",
        "  arrange(desc(count))\n",
        "\n",
        "# Calcular la frecuencia relativa\n",
        "problem_freq <- problem_freq %>%\n",
        "  mutate(relative_freq = count / sum(count))\n",
        "\n",
        "problem_freq"
      ],
      "metadata": {
        "id": "VvgFq4Yep2ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar los datos por frecuencia descendente\n",
        "problem_freq <- problem_freq %>%\n",
        "  arrange(desc(count))\n",
        "\n",
        "options(repr.plot.width=17, repr.plot.height=6)\n",
        "\n",
        "ggplot(problem_freq, aes(y = reorder(problem_desc, count), x = count)) +\n",
        "  geom_bar(stat = \"identity\", fill = 'skyblue') +\n",
        "  geom_text(aes(label = paste0(round(relative_freq * 100, 1), \"%\")), vjust = -0.5, hjust = 0) +\n",
        "  labs(title = \"Frecuencia relativa de problemas de maquinaria\",\n",
        "       y = \"Problema\",\n",
        "       x = \"Cantidad\") +\n",
        "  theme_minimal() +\n",
        "   theme(\n",
        "    axis.text.x = element_text(angle = 45, hjust = 1, size = 12), # Cambia el tamaño del texto del eje x\n",
        "    axis.text.y = element_text(size = 12),                         # Cambia el tamaño del texto del eje y\n",
        "    axis.title.x = element_text(size = 14),                        # Cambia el tamaño del título del eje x\n",
        "    axis.title.y = element_text(size = 14),                        # Cambia el tamaño del título del eje y\n",
        "    plot.title = element_text(size = 16, hjust = 0.5)              # Cambia el tamaño del título del gráfico y lo centra\n",
        "  )"
      ],
      "metadata": {
        "id": "gx5rHH5BVEBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variable \"failure_desc\"**"
      ],
      "metadata": {
        "id": "ecE-YE8KdecU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la frecuencia de fallos de maquinaria\n",
        "failure_freq <- df %>%\n",
        "  group_by(failure_desc) %>%\n",
        "  summarise(count = n()) %>%\n",
        "  arrange(desc(count))\n",
        "\n",
        "# Calcular la frecuencia relativa\n",
        "failure_freq <- failure_freq %>%\n",
        "  mutate(relative_freq = count / sum(count))\n",
        "\n",
        "failure_freq"
      ],
      "metadata": {
        "id": "rTfbZm9qqomH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar los datos por frecuencia descendente\n",
        "failure_freq <- failure_freq %>%\n",
        "  arrange(desc(count))\n",
        "\n",
        "options(repr.plot.width=20, repr.plot.height=6)\n",
        "\n",
        "ggplot(failure_freq, aes(y = reorder(failure_desc, count), x = count)) +\n",
        "  geom_bar(stat = \"identity\", fill = 'skyblue') +\n",
        "  geom_text(aes(label = paste0(round(relative_freq * 100, 1), \"%\")), vjust = -0.5, hjust = 0, size = 5) +  # Etiquetas de porcentaje acumulado\n",
        "  labs(title = \"Frecuencia relativa de fallos\",\n",
        "       y = \"Falla\",\n",
        "       x = \"Cantidad\") +\n",
        "  theme_minimal() +\n",
        "   theme(\n",
        "    axis.text.x = element_text(angle = 45, hjust = 1, size = 12), # Cambia el tamaño del texto del eje x\n",
        "    axis.text.y = element_text(size = 12),                         # Cambia el tamaño del texto del eje y\n",
        "    axis.title.x = element_text(size = 14),                        # Cambia el tamaño del título del eje x\n",
        "    axis.title.y = element_text(size = 14),                        # Cambia el tamaño del título del eje y\n",
        "    plot.title = element_text(size = 16, hjust = 0.5)              # Cambia el tamaño del título del gráfico y lo centra\n",
        "  )"
      ],
      "metadata": {
        "id": "WaI9bflOVnmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variable \"cause_desc\"**"
      ],
      "metadata": {
        "id": "r3vwEy94djV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la frecuencia de causas de fallo\n",
        "cause_freq <- df %>%\n",
        "  group_by(cause_desc) %>%\n",
        "  summarise(count = n()) %>%\n",
        "  arrange(desc(count))\n",
        "\n",
        "# Calcular la frecuencia relativa\n",
        "cause_freq <- cause_freq %>%\n",
        "  mutate(relative_freq = count / sum(count))\n",
        "\n",
        "cause_freq"
      ],
      "metadata": {
        "id": "NGaNNZ6KVp5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar los datos por frecuencia descendente\n",
        "cause_freq <- cause_freq %>%\n",
        "  arrange(desc(count))\n",
        "\n",
        "options(repr.plot.width=20, repr.plot.height=9)\n",
        "\n",
        "ggplot(cause_freq, aes(y = reorder(cause_desc, count), x = count)) +\n",
        "  geom_bar(stat = \"identity\", fill = 'skyblue') +\n",
        "  geom_text(aes(label = paste0(round(relative_freq * 100, 1), \"%\")), vjust = -0.5, hjust = 0,  size = 4) +  # Etiquetas de porcentaje acumulado\n",
        "  labs(title = \"Frecuencia relativa de causas de fallos\",\n",
        "       y = \"Causa\",\n",
        "       x = \"Cantidad\") +\n",
        "  theme_minimal() +\n",
        "  theme(\n",
        "    axis.text.x = element_text(angle = 45, hjust = 1),\n",
        "    axis.text.y = element_text(size = 15, hjust = 0),\n",
        "    axis.title.x = element_text(size = 15),\n",
        "    axis.title.y = element_text(size = 15),\n",
        "    plot.title = element_text(size = 16, hjust = 0.5)\n",
        "  )"
      ],
      "metadata": {
        "id": "WrDVHTrJmi98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignar grupos de frecuencia\n",
        "cause_freq <- cause_freq %>%\n",
        "  mutate(failure_group = case_when(\n",
        "    relative_freq > 0.05 ~ \"Más del 5%\",\n",
        "    relative_freq > 0.03 ~ \"3%-5%\",\n",
        "    relative_freq > 0.02 ~ \"2%-3%\",\n",
        "    relative_freq > 0.01 ~ \"1%-2%\",\n",
        "    TRUE ~ \"Menos del 1%\"\n",
        "  ))\n",
        "\n",
        "# Ordenar los datos por frecuencia descendente\n",
        "cause_freq <- cause_freq %>%\n",
        "  arrange(desc(count))\n",
        "cause_freq"
      ],
      "metadata": {
        "id": "_X6Un4r9ZAXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variable \"action_desc\"**"
      ],
      "metadata": {
        "id": "TK34lSTddn0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la frecuencia de acciones correctivas\n",
        "action_freq <- df %>%\n",
        "  group_by(action_desc) %>%\n",
        "  summarise(count = n()) %>%\n",
        "  arrange(desc(count))\n",
        "\n",
        "# Calcular la frecuencia relativa\n",
        "action_freq <- action_freq %>%\n",
        "  mutate(relative_freq = count / sum(count))\n",
        "\n",
        "action_freq"
      ],
      "metadata": {
        "id": "GAwaYZaSWNmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordenar los datos por frecuencia descendente\n",
        "action_freq <- action_freq %>%\n",
        "  arrange(desc(count))\n",
        "\n",
        "options(repr.plot.width=20, repr.plot.height=9)\n",
        "\n",
        "ggplot(action_freq, aes(y = reorder(action_desc, count), x = count)) +\n",
        "  geom_bar(stat = \"identity\", fill = 'skyblue') +\n",
        "  geom_text(aes(label = paste0(round(relative_freq * 100, 1), \"%\")),\n",
        "            vjust = -0.5, hjust = 0, size = 4) +  # Ajuste del tamaño del texto\n",
        "  labs(title = \"Frecuencia relativa de principales acciones correctivas\",\n",
        "       y = \"Acción Correctiva\",\n",
        "       x = \"Cantidad\") +\n",
        "  theme_minimal() +\n",
        "  theme(\n",
        "    axis.text.x = element_text(angle = 45, hjust = 1),\n",
        "    axis.text.y = element_text(size = 15),\n",
        "    axis.title.x = element_text(size = 15),\n",
        "    axis.title.y = element_text(size = 15, hjust = 1),\n",
        "    plot.title = element_text(size = 16, hjust = 0.5)\n",
        "  )"
      ],
      "metadata": {
        "id": "ayFHnVlgWVBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variable \"parts cost\"**"
      ],
      "metadata": {
        "id": "qFmN5VFtfoZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el boxplot de costo de partes\n",
        "ggplot(df, aes(y = parts_cost)) +\n",
        "  geom_boxplot(fill = 'skyblue', color = 'black') +\n",
        "  labs(title = 'Boxplot de parts cost',\n",
        "       y = 'Costo') +\n",
        "  theme_minimal()"
      ],
      "metadata": {
        "id": "Zjt4gkdBf9Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(df, aes(y = parts_cost)) +\n",
        "  geom_boxplot(fill = 'skyblue', color = 'black', outlier.shape = NA) +\n",
        "  labs(title = 'Boxplot de parts cost',\n",
        "       y = 'Costo') +\n",
        "  theme_minimal() +\n",
        "  ylim(0, 50)"
      ],
      "metadata": {
        "id": "qKdm6TKTfrtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean(df$parts_cost, na.rm = TRUE)      # Media\n",
        "median(df$parts_cost, na.rm = TRUE)    # Mediana\n",
        "sd(df$parts_cost, na.rm = TRUE)        # Desviación estándar\n",
        "var(df$parts_cost, na.rm = TRUE)        # Varianza\n",
        "range(df$parts_cost, na.rm = TRUE)      # Rango"
      ],
      "metadata": {
        "id": "t4qaw4VXcgpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograma de 'parts cost'\n",
        "options(repr.plot.width=9, repr.plot.height=9)\n",
        "\n",
        "hist_parts <- ggplot(df, aes(x = parts_cost)) +\n",
        "  geom_histogram(binwidth = 10, fill = \"green\", color = \"black\", alpha = 0.7) +\n",
        "  labs(title = \"Histograma de Downtime Bruto\",\n",
        "       x = \"Costo\",\n",
        "       y = \"Frecuencia\") +\n",
        "  theme_minimal()\n",
        "\n",
        "# Mostrar histogramas\n",
        "print(hist_parts)"
      ],
      "metadata": {
        "id": "D2-hbbc-Xdy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variable waiting_hours**"
      ],
      "metadata": {
        "id": "GGO_M8Ji4OBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(df, aes(y = waiting_hours)) +\n",
        "  geom_boxplot(fill = 'skyblue', color = 'black', outlier.shape = NA) +\n",
        "  labs(title = 'Boxplot de waiting_hours',\n",
        "       y = 'Horas') +\n",
        "  theme_minimal() +\n",
        "  ylim(0, 50)"
      ],
      "metadata": {
        "id": "bvOSqQr0vpBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ANALISIS DE VARIABLE OBJETIVO \"DOWNTIME GROSS\"**"
      ],
      "metadata": {
        "id": "Xp-Cbd9BXyyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(df$downtime_gross)"
      ],
      "metadata": {
        "id": "PUvAp_f3epQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograma de 'downtimeGross'\n",
        "hist_downtimeGross <- ggplot(df, aes(x = downtime_gross)) +\n",
        "  geom_histogram(binwidth = 10, fill = \"green\", color = \"black\", alpha = 0.7) +\n",
        "  labs(title = \"Histograma de Downtime Bruto\",\n",
        "       x = \"Downtime Bruto (minutos)\",\n",
        "       y = \"Frecuencia\") +\n",
        "  theme_minimal()\n",
        "\n",
        "# Mostrar histogramas\n",
        "print(hist_downtimeGross)"
      ],
      "metadata": {
        "id": "pX3O1eGXcMZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el boxplot de downtime gross\n",
        "options(repr.plot.width=10, repr.plot.height=7)\n",
        "ggplot(df, aes(y = downtime_gross)) +\n",
        "  geom_boxplot(fill = 'skyblue', color = 'black') +\n",
        "  labs(title = 'Boxplot de downtime gross',\n",
        "       y = 'Minutos') +\n",
        "  theme_minimal() +\n",
        "  theme(\n",
        "    axis.text.y = element_text(size = 12), # Tamaño del texto del eje y\n",
        "    axis.title.y = element_text(size = 14), # Tamaño del título del eje y\n",
        "    plot.title = element_text(size = 16)    # Tamaño del título del gráfico\n",
        "  )"
      ],
      "metadata": {
        "id": "6gEeaGnifdRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el boxplot de downtime gross\n",
        "ggplot(df, aes(y = downtime_gross)) +\n",
        "  geom_boxplot(fill = 'skyblue', color = 'black', outlier.shape = NA) +\n",
        "  labs(title = 'Boxplot de downtime gross',\n",
        "       y = 'Minutos') +\n",
        "  theme_minimal() + coord_cartesian(ylim = c(0, 300))"
      ],
      "metadata": {
        "id": "pn4a06xQXhJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el umbral de outliers (95% percentil)\n",
        "outlier_threshold <- quantile(df$downtime_gross, 0.95)\n",
        "\n",
        "# Identificar outliers\n",
        "df$outlier <- ifelse(df$downtime_gross > outlier_threshold, TRUE, FALSE)\n",
        "\n",
        "# Convertir la columna 'Date' a formato de fecha\n",
        "df$date <- as.Date(df$date)\n",
        "\n",
        "# Extraer solo el mes (sin el año) de la fecha\n",
        "df <- df %>%\n",
        "  mutate(Month = format(date, \"%B\")) # Nombre del mes\n",
        "\n",
        "# Agrupar por mes y calcular la frecuencia acumulada de outliers\n",
        "df_outliers <- df %>%\n",
        "  group_by(Month) %>%\n",
        "  summarise(Outliers = sum(outlier), .groups = 'drop') %>%\n",
        "  arrange(match(Month, month.name)) # Ordenar por el orden de los meses\n",
        "\n",
        "# Convertir la columna 'Month' a factor con el orden correcto\n",
        "df_outliers$Month <- factor(df_outliers$Month, levels = month.name)\n",
        "\n",
        "# Crear un gráfico de barras de la frecuencia acumulada de outliers por mes\n",
        "ggplot(df_outliers, aes(x = Month, y = Outliers)) +\n",
        "  geom_bar(stat = \"identity\", fill = \"#1f77b4\", color = 'black') + # Usar un color fijo\n",
        "  labs(title = 'Frecuencia Acumulada de Outliers de Downtime Gross por Mes',\n",
        "       x = 'Mes',\n",
        "       y = 'Cantidad de Outliers') +\n",
        "  theme_minimal() +\n",
        "  theme(\n",
        "    axis.text.x = element_text(angle = 45, hjust = 1, size = 12), # Tamaño y ángulo del texto del eje x\n",
        "    axis.title.x = element_text(size = 14),                      # Tamaño del título del eje x\n",
        "    axis.title.y = element_text(size = 14),                      # Tamaño del título del eje y\n",
        "    plot.title = element_text(size = 16)                         # Tamaño del título del gráfico\n",
        "  )"
      ],
      "metadata": {
        "id": "I55hzrMYfPfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el umbral de outliers (95% percentil)\n",
        "outlier_threshold <- quantile(df$downtime_gross, 0.95)\n",
        "\n",
        "# Identificar outliers en el conjunto de datos original\n",
        "df$outlier <- ifelse(df$downtime_gross > outlier_threshold, TRUE, FALSE)\n",
        "\n",
        "# Filtrar por la operación \"Hem Sleeve\"\n",
        "df_hem_sleeve <- df %>% filter(operation == \"HEM SLEEVE\")\n",
        "\n",
        "# Contar los outliers para la operación \"Hem Sleeve\"\n",
        "outliers_count <- sum(df_hem_sleeve$outlier)\n",
        "\n",
        "# Imprimir el resultado\n",
        "print(outliers_count)"
      ],
      "metadata": {
        "id": "T634bQnkmUIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el umbral de outliers (95% percentil)\n",
        "outlier_threshold <- quantile(df$downtime_gross, 0.95)\n",
        "\n",
        "# Identificar outliers en el conjunto de datos original\n",
        "df$outlier <- ifelse(df$downtime_gross > outlier_threshold, TRUE, FALSE)\n",
        "\n",
        "# Filtrar por la operación \"Hem Sleeve\"\n",
        "df_hem_sleeve <- df %>% filter(operation == \"HEM SLEEVE\")\n",
        "\n",
        "# Contar los outliers para la operación \"Hem Sleeve\"\n",
        "hem_sleeve_outliers_count <- sum(df_hem_sleeve$outlier)\n",
        "\n",
        "# Contar el total de outliers en el DataFrame original\n",
        "total_outliers_count <- sum(df$outlier)\n",
        "\n",
        "# Calcular el porcentaje de outliers de \"Hem Sleeve\" respecto al total de outliers\n",
        "percentage_hem_sleeve_outliers <- (hem_sleeve_outliers_count / total_outliers_count) * 100\n",
        "\n",
        "# Imprimir el resultado\n",
        "print(paste(\"El porcentaje de outliers de 'Hem Sleeve' respecto al total es:\", round(percentage_hem_sleeve_outliers, 2), \"%\"))"
      ],
      "metadata": {
        "id": "Ef0VbKo3mruk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bj8zsGU2qeAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el umbral de outliers (95% percentil)\n",
        "outlier_threshold <- quantile(df$downtime_gross, 0.95)\n",
        "\n",
        "# Identificar outliers en el conjunto de datos original\n",
        "df$outlier <- ifelse(df$downtime_gross > outlier_threshold, TRUE, FALSE)\n",
        "\n",
        "# Calculamos la desviación tipica de la variable downtime_gross\n",
        "sigma_dg = sd(df$downtime_gross)\n",
        "\n",
        "# Calculamos el máximo de la variable downtime_gross\n",
        "max_dg = max(df$downtime_gross)\n",
        "\n",
        "# Agrupamos outliers por el numero de la desviación tipica\n",
        "df_outliers <- df %>% filter(outlier == TRUE) %>%\n",
        "                      #select(downtime_gross) %>%\n",
        "                      mutate(num_sigma = floor(downtime_gross/sigma_dg)) %>%\n",
        "                      group_by(num_sigma) %>%\n",
        "                      summarise(num_outliers = sum(num_sigma), .groups = 'drop')\n",
        "\n",
        "# Crear un gráfico de barras de outliers por el numero de sigmas\n",
        "ggplot(df_outliers, aes(x = num_sigma, y = num_outliers)) +\n",
        "  geom_bar(stat = \"identity\", fill = \"#1f77b4\", color = 'black') + # Usar un color fijo\n",
        "  geom_text(aes(label = num_outliers),vjust = -0.5, hjust = +0.5, size = 4) +  # Ajuste del tamaño del texto\n",
        "  labs(title = paste0('El numero de Outliers de Downtime Gross por el numero\\nde la desviación tipica Sigma = ', round(sigma_dg,2) ),\n",
        "       x = 'Sigmas',\n",
        "       y = 'Cantidad de Outliers') +\n",
        "  theme_minimal() +\n",
        "  theme(\n",
        "    axis.text.x = element_text(hjust = 1, size = 12), # Tamaño del texto del eje x\n",
        "    axis.title.x = element_text(size = 14),           # Tamaño del título del eje x\n",
        "    axis.title.y = element_text(size = 14),           # Tamaño del título del eje y\n",
        "    plot.title = element_text(size = 16)              # Tamaño del título del gráfico\n",
        "  )"
      ],
      "metadata": {
        "id": "ytVw89d4WgOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRUEBA DE HIPOTESIS**"
      ],
      "metadata": {
        "id": "sYsXfTRiNUtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar e importar el paquete nortest\n",
        "if (!require(nortest)) install.packages(\"nortest\")\n",
        "library(nortest)"
      ],
      "metadata": {
        "id": "BFoYRPb8hxjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ad_test <- ad.test(df$downtime_gross)\n",
        "print(ad_test)"
      ],
      "metadata": {
        "id": "UZXqg480hRuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un gráfico Q-Q\n",
        "qqnorm(df$downtime_gross)\n",
        "qqline(df$downtime_gross)"
      ],
      "metadata": {
        "id": "BGMq1Vkvh0kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kruskal.test(downtime_gross ~ failure_desc, data = df)"
      ],
      "metadata": {
        "id": "Xdl3a8VfjIP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"dunn.test\")\n",
        "library(dunn.test)\n",
        "\n",
        "# Realizar la prueba de Dunn\n",
        "dunn.test(df$downtime_gross, df$failure_desc, kw = TRUE)"
      ],
      "metadata": {
        "id": "CxJPpLqlNTta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la mediana de downtime_gross por cada categoría de failure_desc\n",
        "median_values <- df %>%\n",
        "  group_by(failure_desc) %>%\n",
        "  summarise(median_downtime = median(downtime_gross))\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(median_values)"
      ],
      "metadata": {
        "id": "uYeAzZQsmYE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un gráfico de barras de las medianas\n",
        "ggplot(median_values, aes(x = reorder(failure_desc, -median_downtime), y = median_downtime)) +\n",
        "  geom_bar(stat = \"identity\") +\n",
        "  xlab(\"Categoría de Falla\") +\n",
        "  ylab(\"Mediana del Tiempo de Inactividad\") +\n",
        "  ggtitle(\"Mediana del Tiempo de Inactividad por Categoría de Falla\") +\n",
        "  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
      ],
      "metadata": {
        "id": "a6QARzzomYxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELOS GLM**\n",
        "\n"
      ],
      "metadata": {
        "id": "YYWc2PhqQL_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df <- select(df, -wo_type, -outlier, -Month)\n",
        "#Comparar con un glm"
      ],
      "metadata": {
        "id": "zMojStQASpaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(df,5)"
      ],
      "metadata": {
        "id": "xW557DNOma5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer una semilla para reproducibilidad\n",
        "set.seed(123)\n",
        "\n",
        "# Definir proporciones para entrenamiento, validación y prueba\n",
        "train_proportion <- 0.70\n",
        "validation_proportion <- 0.20\n",
        "test_proportion <- 0.10\n",
        "\n",
        "# Calcular tamaños de cada conjunto\n",
        "n <- nrow(df)\n",
        "n_train <- floor(train_proportion * n)\n",
        "n_validation <- floor(validation_proportion * n)\n",
        "n_test <- n - n_train - n_validation  # El resto para prueba\n",
        "\n",
        "# Crear índices para conjunto de entrenamiento, validación y prueba\n",
        "trainIndex <- sample(1:n, n_train)\n",
        "remaining <- setdiff(1:n, trainIndex)\n",
        "validationIndex <- sample(remaining, n_validation)\n",
        "testIndex <- setdiff(remaining, validationIndex)\n",
        "\n",
        "# Crear conjuntos de entrenamiento, validación y prueba\n",
        "train_data1 <- df[trainIndex, ]\n",
        "validation_data1 <- df[validationIndex, ]\n",
        "test_data1 <- df[testIndex, ]\n",
        "\n",
        "# Comprobar las dimensiones de cada conjunto\n",
        "cat(\"Dimensiones del conjunto de entrenamiento: \", dim(train_data1), \"\\n\")\n",
        "cat(\"Dimensiones del conjunto de validación: \", dim(validation_data1), \"\\n\")\n",
        "cat(\"Dimensiones del conjunto de prueba: \", dim(test_data1), \"\\n\")"
      ],
      "metadata": {
        "id": "urg65TgR_ZxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar y ajustar el modelo de regresión lineal\n",
        "#Dividir en entrenamiento, test, validación por ejemplo 70,20,10\n",
        "start_time <- Sys.time()\n",
        "model1 <- glm(downtime_gross~. -equipment -downtime_gross -Days_Between_Failures -date -changed_pcs, data = train_data1)\n",
        "end_time <- Sys.time()\n",
        "training_time1 <- end_time - start_time\n",
        "training_time1\n",
        "# Resumen del modelo\n",
        "summary(model1)"
      ],
      "metadata": {
        "id": "bSJjlo6uIhBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de validación\n",
        "validation_predictions <- predict(model1, newdata = validation_data1)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de validación\n",
        "validation_actuals <- validation_data1$downtime_gross\n",
        "validation_rmse <- sqrt(mean((validation_predictions - validation_actuals)^2))\n",
        "validation_mae <- mean(abs(validation_predictions - validation_actuals))\n",
        "validation_r2 <- 1 - (sum((validation_predictions - validation_actuals)^2) / sum((validation_actuals - mean(validation_actuals))^2))\n",
        "\n",
        "cat(\"Validation RMSE: \", validation_rmse, \"\\n\")\n",
        "cat(\"Validation MAE: \", validation_mae, \"\\n\")\n",
        "cat(\"Validation R-squared: \", validation_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "fWnPu92TbBE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de prueba\n",
        "test_predictions <- predict(model1, newdata = test_data1)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de prueba\n",
        "test_actuals <- test_data1$downtime_gross\n",
        "test_rmse <- sqrt(mean((test_predictions - test_actuals)^2))\n",
        "test_mae <- mean(abs(test_predictions - test_actuals))\n",
        "test_r2 <- 1 - (sum((test_predictions - test_actuals)^2) / sum((test_actuals - mean(test_actuals))^2))\n",
        "\n",
        "cat(\"Test RMSE: \", test_rmse, \"\\n\")\n",
        "cat(\"Test MAE: \", test_mae, \"\\n\")\n",
        "cat(\"Test R-squared: \", test_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "xjnnY2PRiZVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CALCULO DE VARIABLES**"
      ],
      "metadata": {
        "id": "SgZxGsrHQUJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calcular los fallos acumulativos\n",
        "df <- df %>%\n",
        "  group_by(equipment) %>%\n",
        "  mutate(Cumulative_Failure_Count = row_number())"
      ],
      "metadata": {
        "id": "nTXK2CN1arF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el costo acumulado de mantenimiento\n",
        "df <- df %>%\n",
        "  group_by(equipment) %>%\n",
        "  mutate(Cumulative_Maintenance_Cost = cumsum(parts_cost))"
      ],
      "metadata": {
        "id": "_eN_OS-pa8be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer una semilla para reproducibilidad\n",
        "set.seed(123)\n",
        "\n",
        "# Definir proporciones para entrenamiento, validación y prueba\n",
        "train_proportion <- 0.70\n",
        "validation_proportion <- 0.20\n",
        "test_proportion <- 0.10\n",
        "\n",
        "# Calcular tamaños de cada conjunto\n",
        "n <- nrow(df)\n",
        "n_train <- floor(train_proportion * n)\n",
        "n_validation <- floor(validation_proportion * n)\n",
        "n_test <- n - n_train - n_validation  # El resto para prueba\n",
        "\n",
        "# Crear índices para conjunto de entrenamiento, validación y prueba\n",
        "trainIndex <- sample(1:n, n_train)\n",
        "remaining <- setdiff(1:n, trainIndex)\n",
        "validationIndex <- sample(remaining, n_validation)\n",
        "testIndex <- setdiff(remaining, validationIndex)\n",
        "\n",
        "# Crear conjuntos de entrenamiento, validación y prueba\n",
        "train_data2 <- df[trainIndex, ]\n",
        "validation_data2 <- df[validationIndex, ]\n",
        "test_data2 <- df[testIndex, ]\n",
        "\n",
        "# Comprobar las dimensiones de cada conjunto\n",
        "cat(\"Dimensiones del conjunto de entrenamiento: \", dim(train_data2), \"\\n\")\n",
        "cat(\"Dimensiones del conjunto de validación: \", dim(validation_data2), \"\\n\")\n",
        "cat(\"Dimensiones del conjunto de prueba: \", dim(test_data2), \"\\n\")"
      ],
      "metadata": {
        "id": "FBoXjtNkA6bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GLM PARA PREDECIR DOWNTIME CON VARIABLES CALCULADAS**"
      ],
      "metadata": {
        "id": "wNC721DunCQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar y ajustar el modelo de regresión lineal\n",
        "start_time <- Sys.time()\n",
        "model2 <- glm(downtime_gross~. -equipment -downtime_gross -date -changed_pcs, data = train_data2)\n",
        "end_time <- Sys.time()\n",
        "training_time2 <- end_time - start_time\n",
        "training_time2\n",
        "# Resumen del modelo\n",
        "summary(model2)"
      ],
      "metadata": {
        "id": "qtPJcI7SifTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de validación\n",
        "validation_predictions <- predict(model2, newdata = validation_data2)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de validación\n",
        "validation_actuals <- validation_data2$downtime_gross\n",
        "validation_rmse <- sqrt(mean((validation_predictions - validation_actuals)^2))\n",
        "validation_mae <- mean(abs(validation_predictions - validation_actuals))\n",
        "validation_r2 <- 1 - (sum((validation_predictions - validation_actuals)^2) / sum((validation_actuals - mean(validation_actuals))^2))\n",
        "\n",
        "cat(\"Validation RMSE: \", validation_rmse, \"\\n\")\n",
        "cat(\"Validation MAE: \", validation_mae, \"\\n\")\n",
        "cat(\"Validation R-squared: \", validation_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "-HpUEi9YoJWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de prueba (ya calculado, pero repitiendo para claridad)\n",
        "test_predictions <- predict(model2, newdata = test_data2)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de prueba\n",
        "test_actuals <- test_data2$downtime_gross\n",
        "test_rmse <- sqrt(mean((test_predictions - test_actuals)^2))\n",
        "test_mae <- mean(abs(test_predictions - test_actuals))\n",
        "test_r2 <- 1 - (sum((test_predictions - test_actuals)^2) / sum((test_actuals - mean(test_actuals))^2))\n",
        "\n",
        "cat(\"Test RMSE: \", test_rmse, \"\\n\")\n",
        "cat(\"Test MAE: \", test_mae, \"\\n\")\n",
        "cat(\"Test R-squared: \", test_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "-IOvIixsi0DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODELO INCLUYENDO LA VARIABLE \"MACHINE AGE\"**"
      ],
      "metadata": {
        "id": "ErY-VFlBe-jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renombrar la columna 'Equipment' a 'equipment' en df_age\n",
        "df_age <- df_age %>% rename(equipment = Equipment)"
      ],
      "metadata": {
        "id": "5PLrak9YefvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged <- df %>%\n",
        "  left_join(df_age %>% select(equipment, Age), by = \"equipment\")"
      ],
      "metadata": {
        "id": "rHg8j3dFNYjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(df_merged,3)"
      ],
      "metadata": {
        "id": "IZsr48KyNdqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer una semilla para reproducibilidad\n",
        "set.seed(123)\n",
        "\n",
        "# Definir proporciones para entrenamiento, validación y prueba\n",
        "train_proportion <- 0.70\n",
        "validation_proportion <- 0.20\n",
        "test_proportion <- 0.10\n",
        "\n",
        "# Calcular tamaños de cada conjunto\n",
        "n <- nrow(df_merged)\n",
        "n_train <- floor(train_proportion * n)\n",
        "n_validation <- floor(validation_proportion * n)\n",
        "n_test <- n - n_train - n_validation  # El resto para prueba\n",
        "\n",
        "# Crear índices para conjunto de entrenamiento, validación y prueba\n",
        "trainIndex <- sample(1:n, n_train)\n",
        "remaining <- setdiff(1:n, trainIndex)\n",
        "validationIndex <- sample(remaining, n_validation)\n",
        "testIndex <- setdiff(remaining, validationIndex)\n",
        "\n",
        "# Crear conjuntos de entrenamiento, validación y prueba\n",
        "train_data3 <- df_merged[trainIndex, ]\n",
        "validation_data3 <- df_merged[validationIndex, ]\n",
        "test_data3 <- df_merged[testIndex, ]\n",
        "\n",
        "# Comprobar las dimensiones de cada conjunto\n",
        "cat(\"Dimensiones del conjunto de entrenamiento: \", dim(train_data3), \"\\n\")\n",
        "cat(\"Dimensiones del conjunto de validación: \", dim(validation_data3), \"\\n\")\n",
        "cat(\"Dimensiones del conjunto de prueba: \", dim(test_data3), \"\\n\")"
      ],
      "metadata": {
        "id": "zs19kaCzA-Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar y ajustar el modelo de regresión lineal\n",
        "start_time <- Sys.time()\n",
        "model3 <- glm(downtime_gross~. -equipment -downtime_gross -date -changed_pcs, data = train_data3)\n",
        "end_time <- Sys.time()\n",
        "training_time3 <- end_time - start_time\n",
        "training_time3\n",
        "# Resumen del modelo\n",
        "summary(model3)"
      ],
      "metadata": {
        "id": "DS8CsC2lN-GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de validación\n",
        "validation_predictions <- predict(model3, newdata = validation_data3)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de validación\n",
        "validation_actuals <- validation_data3$downtime_gross\n",
        "validation_rmse <- sqrt(mean((validation_predictions - validation_actuals)^2))\n",
        "validation_mae <- mean(abs(validation_predictions - validation_actuals))\n",
        "validation_r2 <- 1 - (sum((validation_predictions - validation_actuals)^2) / sum((validation_actuals - mean(validation_actuals))^2))\n",
        "\n",
        "cat(\"Validation RMSE: \", validation_rmse, \"\\n\")\n",
        "cat(\"Validation MAE: \", validation_mae, \"\\n\")\n",
        "cat(\"Validation R-squared: \", validation_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "vpOsVMZDlDh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de prueba\n",
        "test_predictions <- predict(model3, newdata = test_data3)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de prueba\n",
        "test_actuals <- test_data3$downtime_gross\n",
        "test_rmse <- sqrt(mean((test_predictions - test_actuals)^2))\n",
        "test_mae <- mean(abs(test_predictions - test_actuals))\n",
        "test_r2 <- 1 - (sum((test_predictions - test_actuals)^2) / sum((test_actuals - mean(test_actuals))^2))\n",
        "\n",
        "cat(\"Test RMSE: \", test_rmse, \"\\n\")\n",
        "cat(\"Test MAE: \", test_mae, \"\\n\")\n",
        "cat(\"Test R-squared: \", test_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "73En3KOdoiE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODELO INCLUYENDO LA VARIABLE \"MECHANIC ANTIQUITY\"**"
      ],
      "metadata": {
        "id": "968bHyzjftyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero, calcula la media de antiquity\n",
        "mean_antiquity <- mean(df_mechanic$antiquity, na.rm = TRUE)\n",
        "\n",
        "# Realiza el left join y luego reemplaza los NA en antiquity con la media calculada\n",
        "df_merged2 <- df_merged %>%\n",
        "  left_join(df_mechanic %>% select(mechanic, antiquity), by = \"mechanic\") %>%\n",
        "  mutate(antiquity = ifelse(is.na(antiquity), mean_antiquity, antiquity))"
      ],
      "metadata": {
        "id": "2laPktQUf02l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer una semilla para reproducibilidad\n",
        "set.seed(123)\n",
        "\n",
        "# Definir proporciones para entrenamiento, validación y prueba\n",
        "train_proportion <- 0.70\n",
        "validation_proportion <- 0.20\n",
        "test_proportion <- 0.10\n",
        "\n",
        "# Calcular tamaños de cada conjunto\n",
        "n <- nrow(df_merged2)\n",
        "n_train <- floor(train_proportion * n)\n",
        "n_validation <- floor(validation_proportion * n)\n",
        "n_test <- n - n_train - n_validation  # El resto para prueba\n",
        "\n",
        "# Crear índices para conjunto de entrenamiento, validación y prueba\n",
        "trainIndex <- sample(1:n, n_train)\n",
        "remaining <- setdiff(1:n, trainIndex)\n",
        "validationIndex <- sample(remaining, n_validation)\n",
        "testIndex <- setdiff(remaining, validationIndex)\n",
        "\n",
        "# Crear conjuntos de entrenamiento, validación y prueba\n",
        "train_data4 <- df_merged2[trainIndex, ]\n",
        "validation_data4 <- df_merged2[validationIndex, ]\n",
        "test_data4 <- df_merged2[testIndex, ]\n",
        "\n",
        "# Comprobar las dimensiones de cada conjunto\n",
        "cat(\"Dimensiones del conjunto de entrenamiento: \", dim(train_data4), \"\\n\")\n",
        "cat(\"Dimensiones del conjunto de validación: \", dim(validation_data4), \"\\n\")\n",
        "cat(\"Dimensiones del conjunto de prueba: \", dim(test_data4), \"\\n\")"
      ],
      "metadata": {
        "id": "ETZVlhyyFKos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar y ajustar el modelo de regresión lineal\n",
        "start_time <- Sys.time()\n",
        "model4 <- glm(downtime_gross~. -equipment -downtime_gross -date -changed_pcs, data = train_data4)\n",
        "end_time <- Sys.time()\n",
        "training_time4 <- end_time - start_time\n",
        "training_time4\n",
        "# Resumen del modelo\n",
        "summary(model4)"
      ],
      "metadata": {
        "id": "XfsJj_wGgai2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de validación\n",
        "validation_predictions <- predict(model4, newdata = validation_data4)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de validación\n",
        "validation_actuals <- validation_data4$downtime_gross\n",
        "validation_rmse <- sqrt(mean((validation_predictions - validation_actuals)^2))\n",
        "validation_mae <- mean(abs(validation_predictions - validation_actuals))\n",
        "validation_r2 <- 1 - (sum((validation_predictions - validation_actuals)^2) / sum((validation_actuals - mean(validation_actuals))^2))\n",
        "\n",
        "cat(\"Validation RMSE: \", validation_rmse, \"\\n\")\n",
        "cat(\"Validation MAE: \", validation_mae, \"\\n\")\n",
        "cat(\"Validation R-squared: \", validation_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "GWU-54fxleFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de prueba\n",
        "test_predictions <- predict(model4, newdata = test_data4)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de prueba\n",
        "test_actuals <- test_data4$downtime_gross\n",
        "test_rmse <- sqrt(mean((test_predictions - test_actuals)^2))\n",
        "test_mae <- mean(abs(test_predictions - test_actuals))\n",
        "test_r2 <- 1 - (sum((test_predictions - test_actuals)^2) / sum((test_actuals - mean(test_actuals))^2))\n",
        "\n",
        "cat(\"Test RMSE: \", test_rmse, \"\\n\")\n",
        "cat(\"Test MAE: \", test_mae, \"\\n\")\n",
        "cat(\"Test R-squared: \", test_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "DQwBA8cpo0F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODELO INCLUYENDO LA VARIABLE \"CHANGED_PCS\"**"
      ],
      "metadata": {
        "id": "XnWazNAqyWIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar y ajustar el modelo de regresión lineal\n",
        "start_time <- Sys.time()\n",
        "model5 <- glm(downtime_gross~. -equipment -downtime_gross -date -antiquity, data = train_data4)\n",
        "end_time <- Sys.time()\n",
        "training_time5 <- end_time - start_time\n",
        "training_time5\n",
        "# Resumen del modelo\n",
        "summary(model5)"
      ],
      "metadata": {
        "id": "vIodXx7Uycls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de validación\n",
        "validation_predictions <- predict(model5, newdata = validation_data4)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de validación\n",
        "validation_actuals <- validation_data4$downtime_gross\n",
        "validation_rmse <- sqrt(mean((validation_predictions - validation_actuals)^2))\n",
        "validation_mae <- mean(abs(validation_predictions - validation_actuals))\n",
        "validation_r2 <- 1 - (sum((validation_predictions - validation_actuals)^2) / sum((validation_actuals - mean(validation_actuals))^2))\n",
        "\n",
        "cat(\"Validation RMSE: \", validation_rmse, \"\\n\")\n",
        "cat(\"Validation MAE: \", validation_mae, \"\\n\")\n",
        "cat(\"Validation R-squared: \", validation_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "9O5RaE6SlxJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de prueba\n",
        "test_predictions <- predict(model5, newdata = test_data4)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de prueba\n",
        "test_actuals <- test_data4$downtime_gross\n",
        "test_rmse <- sqrt(mean((test_predictions - test_actuals)^2))\n",
        "test_mae <- mean(abs(test_predictions - test_actuals))\n",
        "test_r2 <- 1 - (sum((test_predictions - test_actuals)^2) / sum((test_actuals - mean(test_actuals))^2))\n",
        "\n",
        "cat(\"Test RMSE: \", test_rmse, \"\\n\")\n",
        "cat(\"Test MAE: \", test_mae, \"\\n\")\n",
        "cat(\"Test R-squared: \", test_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "ic2JDabuo4rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPLEMENTACION DE FRONTWARD**"
      ],
      "metadata": {
        "id": "5xptOdwWQmL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sapply(df_merged2, function(x) sum(is.na(x)))"
      ],
      "metadata": {
        "id": "1TRzX0pOixHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar frontward elimination\n",
        "model_null <- lm(downtime_gross ~ 1, data = train_data4)\n",
        "model_forward <- step(model_null,\n",
        "                      scope = list(lower = model_null, upper = model5),\n",
        "                      direction = \"forward\")\n",
        "model_forward$anova"
      ],
      "metadata": {
        "id": "ZbC7KyFYuvs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formula = as.formula(\"downtime_gross ~ waiting_hours + changed_pcs + mechanic + action_desc +\n",
        "    parts_cost + base_model + cause_desc + failure_desc + Cumulative_Maintenance_Cost +\n",
        "    Cumulative_Failure_Count\")"
      ],
      "metadata": {
        "id": "lAcnoWbu6hlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar y ajustar el modelo de regresión lineal\n",
        "start_time <- Sys.time()\n",
        "model6 <- glm(formula = formula, data = train_data4)\n",
        "end_time <- Sys.time()\n",
        "training_time6 <- end_time - start_time\n",
        "training_time6\n",
        "# Resumen del modelo\n",
        "summary(model6)"
      ],
      "metadata": {
        "id": "B7rr4Ydn6qlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de prueba\n",
        "test_predictions <- predict(model6, newdata = test_data4)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de prueba\n",
        "test_actuals <- test_data4$downtime_gross\n",
        "test_rmse <- sqrt(mean((test_predictions - test_actuals)^2))\n",
        "test_mae <- mean(abs(test_predictions - test_actuals))\n",
        "test_r2 <- 1 - (sum((test_predictions - test_actuals)^2) / sum((test_actuals - mean(test_actuals))^2))\n",
        "\n",
        "cat(\"Test RMSE: \", test_rmse, \"\\n\")\n",
        "cat(\"Test MAE: \", test_mae, \"\\n\")\n",
        "cat(\"Test R-squared: \", test_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "VOQy3450jlAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formula2 = as.formula(\"downtime_gross ~ waiting_hours + changed_pcs*mechanic + action_desc +\n",
        "    parts_cost + base_model + cause_desc + failure_desc + Cumulative_Maintenance_Cost +\n",
        "    Cumulative_Failure_Count\")"
      ],
      "metadata": {
        "id": "qmYCa3-xAbEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODELO CON INTERACCIÓN DE MECHANIC Y CHANGED PIECES**"
      ],
      "metadata": {
        "id": "nQ8Tp2-DUPWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar y ajustar el modelo de regresión lineal\n",
        "# Medir el tiempo de entrenamiento\n",
        "start_time <- Sys.time()\n",
        "model7 <- glm(formula = formula2, data = train_data4)\n",
        "end_time <- Sys.time()\n",
        "training_time8 <- end_time - start_time\n",
        "training_time8\n",
        "# Resumen del modelo\n",
        "summary(model7)"
      ],
      "metadata": {
        "id": "HJDL4i5YAdPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de prueba\n",
        "test_predictions <- predict(model7, newdata = test_data4)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de prueba\n",
        "test_actuals <- test_data4$downtime_gross\n",
        "test_rmse <- sqrt(mean((test_predictions - test_actuals)^2))\n",
        "test_mae <- mean(abs(test_predictions - test_actuals))\n",
        "test_r2 <- 1 - (sum((test_predictions - test_actuals)^2) / sum((test_actuals - mean(test_actuals))^2))\n",
        "\n",
        "cat(\"Test RMSE: \", test_rmse, \"\\n\")\n",
        "cat(\"Test MAE: \", test_mae, \"\\n\")\n",
        "cat(\"Test R-squared: \", test_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "tCNDmCBOCBBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de validación\n",
        "validation_predictions <- predict(model7, newdata = validation_data4)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de validación\n",
        "validation_actuals <- validation_data4$downtime_gross\n",
        "validation_rmse <- sqrt(mean((validation_predictions - validation_actuals)^2))\n",
        "validation_mae <- mean(abs(validation_predictions - validation_actuals))\n",
        "validation_r2 <- 1 - (sum((validation_predictions - validation_actuals)^2) / sum((validation_actuals - mean(validation_actuals))^2))\n",
        "\n",
        "cat(\"Validation RMSE: \", validation_rmse, \"\\n\")\n",
        "cat(\"Validation MAE: \", validation_mae, \"\\n\")\n",
        "cat(\"Validation R-squared: \", validation_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "l9oyd3D9B9nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de todas las variables independientes disponibles\n",
        "variables <- c(\"changed_pcs\", \"mechanic\", \"operation\", \"cause_desc\",\n",
        "               \"problem_desc\", \"Age\", \"base_model\", \"action_desc\",\n",
        "               \"failure_desc\", \"Days_Between_Failures\",\n",
        "               \"Cumulative_Maintenance_Cost\", \"parts_cost\", \"waiting_hours\")\n",
        "\n",
        "# Crear una lista para almacenar los modelos y un data frame para los resultados\n",
        "modelos <- list()\n",
        "resultados <- data.frame(Modelo = character(), Variables = character(), Error = numeric(), R_Squared = numeric(), stringsAsFactors = FALSE)\n",
        "\n",
        "set.seed(123)  # Fijar semilla para reproducibilidad\n",
        "\n",
        "# Bucle para iterar y ajustar 50 modelos\n",
        "for (i in 1:50) {\n",
        "  # Seleccionar aleatoriamente un subconjunto de variables\n",
        "  selected_vars <- sample(variables, size = sample(1:length(variables), 1))  # Tamaño del subconjunto también aleatorio\n",
        "\n",
        "  # Definir la fórmula del modelo usando las variables seleccionadas\n",
        "  formula <- as.formula(paste(\"downtime_gross ~\", paste(selected_vars, collapse = \" + \")))\n",
        "\n",
        "  # Ajustar el modelo GLM\n",
        "  modelo <- glm(formula, data = train_data4, family = gaussian())\n",
        "\n",
        "  # Almacenar el modelo en la lista\n",
        "  modelos[[paste(\"modelo\", i, sep = \"_\")]] <- modelo\n",
        "\n",
        "  # Calcular el Error Absoluto Medio (MAE)\n",
        "  predicciones <- predict(modelo, validation_data4)\n",
        "  mae <- mean(abs(validation_data4$downtime_gross - predicciones))\n",
        "\n",
        "  # Calcular el R cuadrado\n",
        "  ss_total <- sum((validation_data4$downtime_gross - mean(validation_data4$downtime_gross))^2)\n",
        "  ss_residual <- sum((validation_data4$downtime_gross - predicciones)^2)\n",
        "  r_squared <- 1 - (ss_residual / ss_total)\n",
        "\n",
        "  # Almacenar los resultados en el data frame\n",
        "  resultados <- rbind(resultados, data.frame(Modelo = paste(\"Modelo\", i), Variables = paste(selected_vars, collapse = \", \"), Error = mae, R_Squared = r_squared))\n",
        "}\n",
        "\n",
        "# Ver los resultados\n",
        "resultados"
      ],
      "metadata": {
        "id": "-dMR_k9Z8Cj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write.csv(resultados, \"resultados.csv\", row.names = TRUE)"
      ],
      "metadata": {
        "id": "oZnu_BbkcmMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals <- residuals(model6)"
      ],
      "metadata": {
        "id": "OmUjl7qjpBe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qqnorm(residuals)\n",
        "qqline(residuals, col = \"red\")"
      ],
      "metadata": {
        "id": "OoFXdlpKpFSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELO RANDOM FOREST**"
      ],
      "metadata": {
        "id": "OM-Tf0kOOcvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo de Random Forest\n",
        "start_time <- Sys.time()\n",
        "model_rf <- randomForest(downtime_gross ~ waiting_hours + changed_pcs + mechanic + action_desc +\n",
        "    parts_cost + base_model + cause_desc + failure_desc + Cumulative_Maintenance_Cost +\n",
        "    Cumulative_Failure_Count, data = train_data4, importance = TRUE)\n",
        "end_time <- Sys.time()\n",
        "training_time7 <- end_time - start_time\n",
        "training_time7\n",
        "# Ver el resumen del modelo\n",
        "print(model_rf)"
      ],
      "metadata": {
        "id": "0roJOM6JO0NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de validación\n",
        "validation_predictions <- predict(model_rf, newdata = validation_data4)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de validación\n",
        "validation_actuals <- validation_data4$downtime_gross\n",
        "validation_rmse <- sqrt(mean((validation_predictions - validation_actuals)^2))\n",
        "validation_mae <- mean(abs(validation_predictions - validation_actuals))\n",
        "validation_r2 <- 1 - (sum((validation_predictions - validation_actuals)^2) / sum((validation_actuals - mean(validation_actuals))^2))\n",
        "\n",
        "cat(\"Validation RMSE: \", validation_rmse, \"\\n\")\n",
        "cat(\"Validation MAE: \", validation_mae, \"\\n\")\n",
        "cat(\"Validation R-squared: \", validation_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "hs7KBmdpmJ0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de prueba\n",
        "test_predictions <- predict(model_rf, newdata = test_data4)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de prueba\n",
        "test_actuals <- test_data4$downtime_gross\n",
        "test_rmse <- sqrt(mean((test_predictions - test_actuals)^2))\n",
        "test_mae <- mean(abs(test_predictions - test_actuals))\n",
        "test_r2 <- 1 - (sum((test_predictions - test_actuals)^2) / sum((test_actuals - mean(test_actuals))^2))\n",
        "\n",
        "cat(\"Test RMSE: \", test_rmse, \"\\n\")\n",
        "cat(\"Test MAE: \", test_mae, \"\\n\")\n",
        "cat(\"Test R-squared: \", test_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "MP63sdpdPIOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals <- test_data4$downtime_gross - test_predictions"
      ],
      "metadata": {
        "id": "_gFI84ZeSqra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qqnorm(residuals)\n",
        "qqline(residuals, col = \"red\")"
      ],
      "metadata": {
        "id": "o8zC2XTgTOp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver la importancia de las variables\n",
        "importance(model_rf)\n",
        "varImpPlot(model_rf)"
      ],
      "metadata": {
        "id": "xO0MWbdKTWzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"nortest\")\n",
        "library(nortest)"
      ],
      "metadata": {
        "id": "_ve3RmgRHrBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ad_test <- ad.test(residuals)\n",
        "print(ad_test)"
      ],
      "metadata": {
        "id": "zQaCJIyWHteM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELO SVM"
      ],
      "metadata": {
        "id": "Bu10FhfupZT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar el paquete e1071 si no lo tienes\n",
        "install.packages(\"e1071\")\n",
        "\n",
        "# Cargar el paquete\n",
        "library(e1071)"
      ],
      "metadata": {
        "id": "dCcC9hJIpc2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Medir el tiempo de entrenamiento\n",
        "start_time <- Sys.time()\n",
        "\n",
        "# Ajustar el modelo SVM\n",
        "model_svm <- svm(downtime_gross ~ waiting_hours + changed_pcs + mechanic + action_desc +\n",
        "    parts_cost + base_model + cause_desc + failure_desc + Cumulative_Maintenance_Cost +\n",
        "    Cumulative_Failure_Count, data = train_data4, kernel = \"radial\", cost = 1, gamma = 0.1)\n",
        "\n",
        "end_time <- Sys.time()\n",
        "training_time_svm <- end_time - start_time\n",
        "\n",
        "# Mostrar el tiempo de entrenamiento\n",
        "print(training_time_svm)\n",
        "\n",
        "# Ver el resumen del modelo SVM\n",
        "print(model_svm)"
      ],
      "metadata": {
        "id": "6vg6LyPwpdeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de validación usando el modelo SVM\n",
        "validation_predictions_svm <- predict(model_svm, newdata = validation_data4)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de validación\n",
        "validation_actuals <- validation_data4$downtime_gross\n",
        "validation_rmse_svm <- sqrt(mean((validation_predictions_svm - validation_actuals)^2))\n",
        "validation_mae_svm <- mean(abs(validation_predictions_svm - validation_actuals))\n",
        "validation_r2_svm <- 1 - (sum((validation_predictions_svm - validation_actuals)^2) / sum((validation_actuals - mean(validation_actuals))^2))\n",
        "\n",
        "cat(\"Validation RMSE (SVM): \", validation_rmse_svm, \"\\n\")\n",
        "cat(\"Validation MAE (SVM): \", validation_mae_svm, \"\\n\")\n",
        "cat(\"Validation R-squared (SVM): \", validation_r2_svm, \"\\n\")"
      ],
      "metadata": {
        "id": "nx3f8N93pqbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de prueba usando el modelo SVM\n",
        "test_predictions_svm <- predict(model_svm, newdata = test_data4)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de prueba\n",
        "test_actuals <- test_data4$downtime_gross\n",
        "test_rmse_svm <- sqrt(mean((test_predictions_svm - test_actuals)^2))\n",
        "test_mae_svm <- mean(abs(test_predictions_svm - test_actuals))\n",
        "test_r2_svm <- 1 - (sum((test_predictions_svm - test_actuals)^2) / sum((test_actuals - mean(test_actuals))^2))\n",
        "\n",
        "cat(\"Test RMSE (SVM): \", test_rmse_svm, \"\\n\")\n",
        "cat(\"Test MAE (SVM): \", test_mae_svm, \"\\n\")\n",
        "cat(\"Test R-squared (SVM): \", test_r2_svm, \"\\n\")"
      ],
      "metadata": {
        "id": "11YQb7YOp9Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc-oRD8WR-wQ"
      },
      "source": [
        "# **MODELO GRADIENT BOOSTING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0aH9RDcwf96"
      },
      "source": [
        "**Cargamos la librería gbm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WiOYrGiR4We"
      },
      "outputs": [],
      "source": [
        "install.packages('gbm')\n",
        "library(gbm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88v7PbgQu1B_"
      },
      "outputs": [],
      "source": [
        "dim(train_data4)\n",
        "dim(validation_data4)\n",
        "dim(test_data4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H9joOK-vRop"
      },
      "outputs": [],
      "source": [
        "glimpse(test_data4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCxuz30GwI7Z"
      },
      "source": [
        "**Numerización**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh4BsWtxwASA"
      },
      "source": [
        "Convertimos a numérico las variables **operation, base_model, problem_desc, failure_desc, cause_desc, action_desc, mechanic** que contienen datos textuales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXQbieb4x6BI"
      },
      "outputs": [],
      "source": [
        "install.packages(\"superml\")\n",
        "library(superml)\n",
        "library(scales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cuc-9LEJwD2R"
      },
      "outputs": [],
      "source": [
        "encoder1 <- LabelEncoder$new()\n",
        "encoder2 <- LabelEncoder$new()\n",
        "encoder3 <- LabelEncoder$new()\n",
        "encoder4 <- LabelEncoder$new()\n",
        "encoder5 <- LabelEncoder$new()\n",
        "encoder6 <- LabelEncoder$new()\n",
        "encoder7 <- LabelEncoder$new()\n",
        "\n",
        "data_for_gb <- rbind(rbind(train_data4, validation_data4), test_data4)\n",
        "\n",
        "data_for_gb$operation <- encoder1$fit_transform(data_for_gb$operation)\n",
        "data_for_gb$base_model <- encoder2$fit_transform(data_for_gb$base_model)\n",
        "data_for_gb$problem_desc <- encoder3$fit_transform(data_for_gb$problem_desc)\n",
        "data_for_gb$failure_desc <- encoder4$fit_transform(data_for_gb$failure_desc)\n",
        "data_for_gb$cause_desc <- encoder5$fit_transform(data_for_gb$cause_desc)\n",
        "data_for_gb$action_desc <- encoder6$fit_transform(data_for_gb$action_desc)\n",
        "data_for_gb$mechanic <- encoder7$fit_transform(data_for_gb$mechanic)\n",
        "\n",
        "data_for_gb$changed_pcs <- rescale(data_for_gb$changed_pcs)\n",
        "data_for_gb$mechanic <- rescale(data_for_gb$mechanic)\n",
        "data_for_gb$operation <- rescale(data_for_gb$operation)\n",
        "data_for_gb$cause_desc <- rescale(data_for_gb$cause_desc)\n",
        "data_for_gb$problem_desc <- rescale(data_for_gb$problem_desc)\n",
        "data_for_gb$Age <- rescale(data_for_gb$Age)\n",
        "data_for_gb$base_model <- rescale(data_for_gb$base_model)\n",
        "data_for_gb$action_desc <- rescale(data_for_gb$action_desc)\n",
        "data_for_gb$failure_desc <- rescale(data_for_gb$failure_desc)\n",
        "data_for_gb$Days_Between_Failures <- rescale(data_for_gb$Days_Between_Failures)\n",
        "data_for_gb$Cumulative_Maintenance_Cost <- rescale(data_for_gb$Cumulative_Maintenance_Cost)\n",
        "data_for_gb$parts_cost <- rescale(data_for_gb$parts_cost)\n",
        "\n",
        "head(data_for_gb, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRiLTYW1_hh8"
      },
      "outputs": [],
      "source": [
        "# Crear conjuntos de entrenamiento, validación y prueba para el modelo de Gradient Boosting\n",
        "\n",
        "train_data5 <- data_for_gb[1:nrow(train_data4),]\n",
        "validation_data5 <- data_for_gb[(nrow(train_data4)+1):(nrow(train_data4) + nrow(validation_data4)),]\n",
        "test_data5 <- data_for_gb[(nrow(train_data4) + nrow(validation_data4)+1):(nrow(train_data4) + nrow(validation_data4)+nrow(test_data4)),]\n",
        "\n",
        "dim(train_data5)\n",
        "dim(validation_data5)\n",
        "dim(test_data5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiUS5g4EJdYU"
      },
      "outputs": [],
      "source": [
        "formula"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelización y Evaluación**"
      ],
      "metadata": {
        "id": "X3aoMK9X9BC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos el modelo para varios valores de la máxima profundidad de árboles (max_depth) de 1 a 30."
      ],
      "metadata": {
        "id": "Gaq25Kgz9ZO8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgrcfGR1IwbG"
      },
      "outputs": [],
      "source": [
        "n_estimators <- 100\n",
        "learning_rate <-  0.01\n",
        "\n",
        "max_depth_list <- c()\n",
        "train_rmse_list <- c()\n",
        "train_mae_list <- c()\n",
        "train_r2_list <- c()\n",
        "val_rmse_list <-c()\n",
        "val_mae_list <- c()\n",
        "val_r2_list <- c()\n",
        "\n",
        "for (max_depth in 1:30) {\n",
        " cat(\"\\nLa profundidad maxima de árboles: \", max_depth, \"\\n\")\n",
        " start_time <- Sys.time()\n",
        " model_gbm = gbm(downtime_gross ~ waiting_hours + changed_pcs + mechanic + action_desc +\n",
        "    parts_cost + base_model + cause_desc + failure_desc + Cumulative_Maintenance_Cost +\n",
        "    Cumulative_Failure_Count, data = train_data5,\n",
        "                 distribution = \"gaussian\",\n",
        "                # cv.folds = 10,\n",
        "                 shrinkage = learning_rate,\n",
        "                 n.trees = n_estimators,\n",
        "                 interaction.depth = max_depth)\n",
        " end_time <- Sys.time()\n",
        " training_time8 <- end_time - start_time\n",
        " training_time8\n",
        "\n",
        " # Predecir con el conjunto de entrenamiento\n",
        " train_predictions <- predict(model_gbm, newdata = train_data5)\n",
        "\n",
        " # Calcular métricas de rendimiento para el conjunto de entrenamiento\n",
        " train_actuals <- train_data5$downtime_gross\n",
        " train_rmse <- sqrt(mean((train_predictions - train_actuals)^2))\n",
        " train_mae <- mean(abs(train_predictions - train_actuals))\n",
        " train_r2 <- 1 - (sum((train_predictions - train_actuals)^2) / sum((train_actuals - mean(train_actuals))^2))\n",
        "\n",
        " cat(\"Train RMSE: \", train_rmse, \"\\n\")\n",
        " cat(\"Train MAE: \", train_mae, \"\\n\")\n",
        " cat(\"Train R-squared: \", train_r2, \"\\n\\n\")\n",
        "\n",
        " # Predecir con el conjunto de validación\n",
        " validation_predictions <- predict(model_gbm, newdata = validation_data5)\n",
        "\n",
        " # Calcular métricas de rendimiento para el conjunto de validación\n",
        " validation_actuals <- validation_data5$downtime_gross\n",
        " validation_rmse <- sqrt(mean((validation_predictions - validation_actuals)^2))\n",
        " validation_mae <- mean(abs(validation_predictions - validation_actuals))\n",
        " validation_r2 <- 1 - (sum((validation_predictions - validation_actuals)^2) / sum((validation_actuals - mean(validation_actuals))^2))\n",
        "\n",
        " cat(\"Validation RMSE: \", validation_rmse, \"\\n\")\n",
        " cat(\"Validation MAE: \", validation_mae, \"\\n\")\n",
        " cat(\"Validation R-squared: \", validation_r2, \"\\n\")\n",
        "\n",
        " max_depth_list[max_depth] <- max_depth\n",
        " train_rmse_list[max_depth] <- train_rmse\n",
        " train_mae_list[max_depth] <- train_mae\n",
        " train_r2_list[max_depth] <- train_r2\n",
        " val_rmse_list[max_depth] <-validation_rmse\n",
        " val_mae_list[max_depth] <- validation_mae\n",
        " val_r2_list[max_depth] <- validation_r2\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPQ9rF_S_9Cq"
      },
      "outputs": [],
      "source": [
        "df_metricas <- data.frame(max_depth_list, train_rmse_list, train_mae_list, train_r2_list, val_rmse_list,val_mae_list, val_r2_list)\n",
        "colnames(df_metricas) <- c(\"max_depth\", \"train_rmse\", \"train_mae\", \"train_r2\", \"val_rmse\", \"val_mae\", \"val_r2\")\n",
        "df_metricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJOH9WiZCMhp"
      },
      "outputs": [],
      "source": [
        "ggplot(df_metricas, aes(x = max_depth)) +\n",
        "    geom_line(aes(y = train_rmse, color = \"Train RMSE\")) +\n",
        "    geom_line(aes(y = val_rmse, color = \"Validation RMSE\")) +\n",
        "    labs(title = \"RMSE por la profundidad de los Arboles para Gradient Boosting\",\n",
        "         x = \"Profundidad máxima de árboles\",\n",
        "         y = \"RMSE\") +\n",
        "    scale_color_manual(values = c(\"Train RMSE\" = \"blue\", \"Validation RMSE\" = \"red\")) +\n",
        "    theme_minimal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFprICbeEHoW"
      },
      "outputs": [],
      "source": [
        "ggplot(df_metricas, aes(x = max_depth)) +\n",
        "    geom_line(aes(y = train_r2, color = \"Train R2\")) +\n",
        "    geom_line(aes(y = val_r2, color = \"Validation R2\")) +\n",
        "    labs(title = \"R2 por la profundidad de los Arboles para Gradient Boosting\",\n",
        "         x = \"Profundidad máxima de árboles\",\n",
        "         y = \"R2\") +\n",
        "    scale_color_manual(values = c(\"Train R2\" = \"blue\", \"Validation R2\" = \"red\")) +\n",
        "    theme_minimal()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos el modelo con valor optimo de max_depth = 7 para diferentes valores dl numero de árboles (n_estimators)"
      ],
      "metadata": {
        "id": "IyCXy4Db-D1j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNLtjA_2oyDb"
      },
      "outputs": [],
      "source": [
        "learning_rate <-  0.01\n",
        "max_depth <- 7\n",
        "\n",
        "n_estimators_list <- c()\n",
        "train_rmse_list <- c()\n",
        "train_mae_list <- c()\n",
        "train_r2_list <- c()\n",
        "val_rmse_list <-c()\n",
        "val_mae_list <- c()\n",
        "val_r2_list <- c()\n",
        "i <- 1\n",
        "\n",
        "for (n_estimators in seq(100, 2000, by=100)) {\n",
        " cat(\"\\nEl numero árboles: \", n_estimators, \"\\n\")\n",
        " start_time <- Sys.time()\n",
        " model_gbm = gbm(downtime_gross ~ waiting_hours + changed_pcs + mechanic + action_desc +\n",
        "    parts_cost + base_model + cause_desc + failure_desc + Cumulative_Maintenance_Cost +\n",
        "    Cumulative_Failure_Count, data = train_data5,\n",
        "                 distribution = \"gaussian\",\n",
        "                # cv.folds = 10,\n",
        "                 shrinkage = learning_rate,\n",
        "                 n.trees = n_estimators,\n",
        "                 interaction.depth = max_depth)\n",
        " end_time <- Sys.time()\n",
        " training_time8 <- end_time - start_time\n",
        " cat(\"Training time: \", training_time8, \"\\n\")\n",
        "\n",
        " # Predecir con el conjunto de entrenamiento\n",
        " train_predictions <- predict(model_gbm, newdata = train_data5)\n",
        "\n",
        " # Calcular métricas de rendimiento para el conjunto de entrenamiento\n",
        " train_actuals <- train_data5$downtime_gross\n",
        " train_rmse <- sqrt(mean((train_predictions - train_actuals)^2))\n",
        " train_mae <- mean(abs(train_predictions - train_actuals))\n",
        " train_r2 <- 1 - (sum((train_predictions - train_actuals)^2) / sum((train_actuals - mean(train_actuals))^2))\n",
        "\n",
        " cat(\"Train RMSE: \", train_rmse, \"\\n\")\n",
        " cat(\"Train MAE: \", train_mae, \"\\n\")\n",
        " cat(\"Train R-squared: \", train_r2, \"\\n\\n\")\n",
        "\n",
        " # Predecir con el conjunto de validación\n",
        " validation_predictions <- predict(model_gbm, newdata = validation_data5)\n",
        "\n",
        " # Calcular métricas de rendimiento para el conjunto de validación\n",
        " validation_actuals <- validation_data5$downtime_gross\n",
        " validation_rmse <- sqrt(mean((validation_predictions - validation_actuals)^2))\n",
        " validation_mae <- mean(abs(validation_predictions - validation_actuals))\n",
        " validation_r2 <- 1 - (sum((validation_predictions - validation_actuals)^2) / sum((validation_actuals - mean(validation_actuals))^2))\n",
        "\n",
        " cat(\"Validation RMSE: \", validation_rmse, \"\\n\")\n",
        " cat(\"Validation MAE: \", validation_mae, \"\\n\")\n",
        " cat(\"Validation R-squared: \", validation_r2, \"\\n\")\n",
        "\n",
        " n_estimators_list[i] <- n_estimators\n",
        " train_rmse_list[i] <- train_rmse\n",
        " train_mae_list[i] <- train_mae\n",
        " train_r2_list[i] <- train_r2\n",
        " val_rmse_list[i] <-validation_rmse\n",
        " val_mae_list[i] <- validation_mae\n",
        " val_r2_list[i] <- validation_r2\n",
        " i <- i + 1\n",
        "\n",
        "}\n",
        "\n",
        "df_metricas <- data.frame(n_estimators_list, train_rmse_list, train_mae_list, train_r2_list, val_rmse_list,val_mae_list, val_r2_list)\n",
        "colnames(df_metricas) <- c(\"n_estimators\", \"train_rmse\", \"train_mae\", \"train_r2\", \"val_rmse\", \"val_mae\", \"val_r2\")\n",
        "df_metricas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onqZ852xxuzL"
      },
      "outputs": [],
      "source": [
        "ggplot(df_metricas, aes(x = n_estimators)) +\n",
        "    geom_line(aes(y = train_rmse, color = \"Train RMSE\")) +\n",
        "    geom_line(aes(y = val_rmse, color = \"Validation RMSE\")) +\n",
        "    labs(title = \"RMSE por el numero de los Arboles para Gradient Boosting\",\n",
        "         x = \"Numero de árboles\",\n",
        "         y = \"RMSE\") +\n",
        "    scale_color_manual(values = c(\"Train RMSE\" = \"blue\", \"Validation RMSE\" = \"red\")) +\n",
        "    theme_minimal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7rMZLCtxFZT"
      },
      "outputs": [],
      "source": [
        "ggplot(df_metricas, aes(x = n_estimators)) +\n",
        "    geom_line(aes(y = train_r2, color = \"Train R2\")) +\n",
        "    geom_line(aes(y = val_r2, color = \"Validation R2\")) +\n",
        "    labs(title = \"R2 por el numero de los Arboles para Gradient Boosting\",\n",
        "         x = \"Numero de árboles\",\n",
        "         y = \"R2\") +\n",
        "    scale_color_manual(values = c(\"Train R2\" = \"blue\", \"Validation R2\" = \"red\")) +\n",
        "    theme_minimal()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubP30Opmxc0b"
      },
      "outputs": [],
      "source": [
        "df_metricas[df_metricas$n_estimators==500,]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos el modelo optimal con max_depth = 7 y n_estimators = 500"
      ],
      "metadata": {
        "id": "E27FE3x4_HBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "formula"
      ],
      "metadata": {
        "id": "8wTnMzvWzKH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate <-  0.01\n",
        "max_depth <- 7\n",
        "n_estimators <- 500\n",
        "\n",
        "start_time <- Sys.time()\n",
        "model_gbm = gbm(formula=formula, data = train_data5,\n",
        "                 distribution = \"gaussian\",\n",
        "                 #cv.folds = 10,\n",
        "                 shrinkage = learning_rate,\n",
        "                 n.trees = n_estimators,\n",
        "                 interaction.depth = max_depth)\n",
        "end_time <- Sys.time()\n",
        "training_time8 <- end_time - start_time\n",
        "cat(\"Training time: \", training_time8, \"\\n\")\n",
        "\n",
        "# Predecir con el conjunto de entrenamiento\n",
        "train_predictions <- predict(model_gbm, newdata = train_data5)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de entrenamiento\n",
        "train_actuals <- train_data5$downtime_gross\n",
        "train_rmse <- sqrt(mean((train_predictions - train_actuals)^2))\n",
        "train_mae <- mean(abs(train_predictions - train_actuals))\n",
        "train_r2 <- 1 - (sum((train_predictions - train_actuals)^2) / sum((train_actuals - mean(train_actuals))^2))\n",
        "\n",
        "cat(\"Train RMSE: \", train_rmse, \"\\n\")\n",
        "cat(\"Train MAE: \", train_mae, \"\\n\")\n",
        "cat(\"Train R-squared: \", train_r2, \"\\n\\n\")\n",
        "\n",
        "# Predecir con el conjunto de validación\n",
        "test_predictions <- predict(model_gbm, newdata = test_data5)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de validación\n",
        "test_actuals <- test_data5$downtime_gross\n",
        "test_rmse <- sqrt(mean((test_predictions - test_actuals)^2))\n",
        "test_mae <- mean(abs(test_predictions - test_actuals))\n",
        "test_r2 <- 1 - (sum((test_predictions - test_actuals)^2) / sum((test_actuals - mean(test_actuals))^2))\n",
        "\n",
        "cat(\"Test RMSE: \", test_rmse, \"\\n\")\n",
        "cat(\"Test MAE: \", test_mae, \"\\n\")\n",
        "cat(\"Test R-squared: \", test_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "Av2yXOsq_aU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELO RED NEURAL**"
      ],
      "metadata": {
        "id": "rYogG8YWpL3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"tensorflow\")\n",
        "library(tensorflow)\n",
        "install.packages(\"keras3\")\n",
        "library(keras3)\n",
        "install.packages(\"tidyverse\")\n",
        "library(tidyverse)\n",
        "install.packages(\"tidymodels\")\n",
        "library(tidymodels)"
      ],
      "metadata": {
        "id": "9et-AQ-NpxJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim(train_data4)\n",
        "dim(validation_data4)\n",
        "dim(test_data4)"
      ],
      "metadata": {
        "id": "Ok_r2MP4uAzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formula"
      ],
      "metadata": {
        "id": "6Jry97NWRJhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creamos el conjunto de datos del entrenamiento y de la evaluación**"
      ],
      "metadata": {
        "id": "0UwKMSeivUim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder1 <- LabelEncoder$new()\n",
        "encoder2 <- LabelEncoder$new()\n",
        "encoder3 <- LabelEncoder$new()\n",
        "encoder4 <- LabelEncoder$new()\n",
        "encoder5 <- LabelEncoder$new()\n",
        "encoder6 <- LabelEncoder$new()\n",
        "encoder7 <- LabelEncoder$new()\n",
        "\n",
        "data_for_rn <- rbind(rbind(train_data4, validation_data4), test_data4)\n",
        "\n",
        "data_for_rn$operation <- encoder1$fit_transform(data_for_rn$operation)\n",
        "data_for_rn$base_model <- encoder2$fit_transform(data_for_rn$base_model)\n",
        "data_for_rn$problem_desc <- encoder3$fit_transform(data_for_rn$problem_desc)\n",
        "data_for_rn$failure_desc <- encoder4$fit_transform(data_for_rn$failure_desc)\n",
        "data_for_rn$cause_desc <- encoder5$fit_transform(data_for_rn$cause_desc)\n",
        "data_for_rn$action_desc <- encoder6$fit_transform(data_for_rn$action_desc)\n",
        "data_for_rn$mechanic <- encoder7$fit_transform(data_for_rn$mechanic)\n",
        "\n",
        "data_for_rn <- data_for_rn[, c(\"waiting_hours\", \"changed_pcs\", \"mechanic\", \"action_desc\",\n",
        "                               \"parts_cost\", \"base_model\", \"cause_desc\", \"failure_desc\",\n",
        "                               \"Cumulative_Maintenance_Cost\", \"Cumulative_Failure_Count\",\n",
        "                               \"downtime_gross\")]\n",
        "head(data_for_rn, 6)\n"
      ],
      "metadata": {
        "id": "tEM7ZvkOvohu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(data_for_rn)"
      ],
      "metadata": {
        "id": "Jp_1Tovqod8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cambiamos los valores NA de la variable Age por la mediana\n",
        "#mediana_Age <- median(data_for_rn$Age, na.rm = TRUE)\n",
        "#data_for_rn$Age[is.na(data_for_rn$Age)] <- mediana_Age\n",
        "#summary(data_for_rn$Age)"
      ],
      "metadata": {
        "id": "vyPSDbTbosBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear conjuntos de entrenamiento y de prueba para el modelo Red Neural\n",
        "\n",
        "train_data6 <- data_for_rn[1:(nrow(train_data4) + nrow(validation_data4)),]\n",
        "test_data6 <- data_for_rn[(nrow(train_data4) + nrow(validation_data4)+1):(nrow(train_data4) + nrow(validation_data4)+nrow(test_data4)),]\n",
        "\n",
        "dim(train_data6)\n",
        "dim(test_data6)"
      ],
      "metadata": {
        "id": "4VBmFXFgY1Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividimos datasets por características y etiquetas para entrenar luego el modelo\n",
        "\n",
        "X_train <- as.matrix(select(train_data6, -downtime_gross))\n",
        "Y_train <- as.matrix(select(train_data6, downtime_gross))\n",
        "\n",
        "X_test <- as.matrix(select(test_data6, -downtime_gross))\n",
        "Y_test <- as.matrix(select(test_data6, downtime_gross))\n",
        "\n",
        "print(\"Dimenciones del conjunto de datos de entrenamiento: \")\n",
        "dim(X_train)\n",
        "dim(Y_train)\n",
        "\n",
        "print(\"Dimenciones del conjunto de datos de prueba: \")\n",
        "dim(X_test)\n",
        "dim(Y_test)"
      ],
      "metadata": {
        "id": "NsGKfMbhbs0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creamos el modelo optimo**"
      ],
      "metadata": {
        "id": "1i4Iw3-kfW8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer <- layer_normalization(axis = -1L)\n",
        "normalizer %>% adapt(X_train)"
      ],
      "metadata": {
        "id": "gM0yz-f3faJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(normalizer$mean)"
      ],
      "metadata": {
        "id": "My81GtAbkypX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dos capas leneales, epochs = 30"
      ],
      "metadata": {
        "id": "Xtws3Vmz6n06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rn_optimo <- keras_model_sequential(shape=c(10)) %>%\n",
        "    normalizer() %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(1)\n",
        "\n",
        "model_rn_optimo %>% compile(\n",
        "    loss = 'mean_squared_error',\n",
        "    optimizer = optimizer_adam(0.01),\n",
        "    metrics = \"r2_score\")\n",
        "\n",
        "summary(model_rn_optimo)"
      ],
      "metadata": {
        "id": "dOdX0oNtlyMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history <- model_rn_optimo %>% fit(\n",
        "  x = X_train,\n",
        "  y = Y_train,\n",
        "  validation_split = 0.2,\n",
        "  verbose = 2,\n",
        "  epochs = 30)"
      ],
      "metadata": {
        "id": "O-0wsd6vmSCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history)"
      ],
      "metadata": {
        "id": "98iwqdurpDhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "id": "To9g-4EfpR1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir con el conjunto de entrenamiento\n",
        "train_predictions <- predict(model_rn_optimo, X_train)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de entrenamiento\n",
        "train_actuals <- Y_train #train_data6$downtime_gross\n",
        "train_rmse <- sqrt(mean((train_predictions - train_actuals)^2))\n",
        "train_mae <- mean(abs(train_predictions - train_actuals))\n",
        "train_r2 <- 1 - (sum((train_predictions - train_actuals)^2) / sum((train_actuals - mean(train_actuals))^2))\n",
        "\n",
        "cat(\"Train RMSE: \", train_rmse, \"\\n\")\n",
        "cat(\"Train MAE: \", train_mae, \"\\n\")\n",
        "cat(\"Train R-squared: \", train_r2, \"\\n\\n\")\n",
        "\n",
        "# Predecir con el conjunto de validación\n",
        "test_predictions <- predict(model_rn_optimo, X_test)\n",
        "\n",
        "# Calcular métricas de rendimiento para el conjunto de validación\n",
        "test_actuals <- Y_test #test_data6$downtime_gross\n",
        "test_rmse <- sqrt(mean((test_predictions - test_actuals)^2))\n",
        "test_mae <- mean(abs(test_predictions - test_actuals))\n",
        "test_r2 <- 1 - (sum((test_predictions - test_actuals)^2) / sum((test_actuals - mean(test_actuals))^2))\n",
        "\n",
        "cat(\"Test RMSE: \", test_rmse, \"\\n\")\n",
        "cat(\"Test MAE: \", test_mae, \"\\n\")\n",
        "cat(\"Test R-squared: \", test_r2, \"\\n\")"
      ],
      "metadata": {
        "id": "d0W1BIQmpasu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pruebas de modelos con parametros diferentes**"
      ],
      "metadata": {
        "id": "1t83uZwop-jS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dos capas lineales, epochs = 100, loss = mean_squared_error, learning_rate = 0.01"
      ],
      "metadata": {
        "id": "5til4bQA6C9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rn <- keras_model_sequential(shape=c(10)) %>%\n",
        "    normalizer() %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(1)\n",
        "\n",
        "model_rn %>% compile(\n",
        "    loss = 'mean_squared_error',\n",
        "    optimizer = optimizer_adam(0.01),\n",
        "    metrics = \"r2_score\")\n",
        "\n",
        "summary(model_rn)"
      ],
      "metadata": {
        "id": "BHX6uORRus80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history <- model_rn %>% fit(\n",
        "  x = X_train,\n",
        "  y = Y_train,\n",
        "  validation_split = 0.2,\n",
        "  verbose = 2,\n",
        "  epochs = 100)"
      ],
      "metadata": {
        "id": "-T0z38a9cKK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history)"
      ],
      "metadata": {
        "id": "t7XZBnUdfwjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "id": "6Nyrsm73nzY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dos capas lineale, epochs = 30, loss = mean_absolute_error, learning_rate = 0.01"
      ],
      "metadata": {
        "id": "y1X6Yyc065H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rn1 <- keras_model_sequential(shape=c(10)) %>%\n",
        "    normalizer() %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(1)\n",
        "\n",
        "model_rn1 %>% compile(\n",
        "    loss = 'mean_absolute_error',\n",
        "    optimizer = optimizer_adam(0.01),\n",
        "    metrics = \"r2_score\")\n",
        "\n",
        "summary(model_rn1)"
      ],
      "metadata": {
        "id": "HBOv2FgW7MvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history1 <- model_rn1 %>% fit(\n",
        "  x = X_train,\n",
        "  y = Y_train,\n",
        "  validation_split = 0.2,\n",
        "  verbose = 2,\n",
        "  epochs = 30)"
      ],
      "metadata": {
        "id": "yhKLuOdJ7tiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history1"
      ],
      "metadata": {
        "id": "b33Rao2j8-Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history1)"
      ],
      "metadata": {
        "id": "NlJ7mT3G9FSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una capa lineal, leraning_rate = 0.01"
      ],
      "metadata": {
        "id": "OshR09xG9TKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rn2 <- keras_model_sequential(shape=c(10)) %>%\n",
        "    normalizer() %>%\n",
        "    layer_dense(1)\n",
        "\n",
        "model_rn2 %>% compile(\n",
        "    loss = 'mean_squared_error',\n",
        "    optimizer = optimizer_adam(0.01),\n",
        "    metrics = \"r2_score\")\n",
        "\n",
        "summary(model_rn2)"
      ],
      "metadata": {
        "id": "BOcgMTBWVL4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 <- model_rn2 %>% fit(\n",
        "  x = X_train,\n",
        "  y = Y_train,\n",
        "  validation_split = 0.2,\n",
        "  verbose = 2,\n",
        "  epochs = 30)"
      ],
      "metadata": {
        "id": "LidOKyKxVudD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history2)\n",
        "history2"
      ],
      "metadata": {
        "id": "zRQOcgYPX3Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dos capas lineale, epochs = 30, loss = mean_squared_error, learning_rate = 0.001"
      ],
      "metadata": {
        "id": "065118Dd_eqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rn3 <- keras_model_sequential(shape=c(10)) %>%\n",
        "    normalizer() %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(1)\n",
        "\n",
        "model_rn3 %>% compile(\n",
        "    loss = 'mean_squared_error',\n",
        "    optimizer = optimizer_adam(0.001),\n",
        "    metrics = \"r2_score\")\n",
        "\n",
        "summary(model_rn3)"
      ],
      "metadata": {
        "id": "XU7H7Zh7hLeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history3 <- model_rn3 %>% fit(\n",
        "  x = X_train,\n",
        "  y = Y_train,\n",
        "  validation_split = 0.2,\n",
        "  verbose = 2,\n",
        "  epochs = 50)\n",
        "\n",
        "plot(history3)\n",
        "history3"
      ],
      "metadata": {
        "id": "SAhPfjw9hdKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una capa lineal, loss = mean_absolute_error, learning_rate = 0.001"
      ],
      "metadata": {
        "id": "ICQGpn53FVCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rn4 <- keras_model_sequential(shape=c(10)) %>%\n",
        "    normalizer() %>%\n",
        "    layer_dense(1)\n",
        "\n",
        "model_rn4 %>% compile(\n",
        "    loss = 'mean_absolute_error',\n",
        "    optimizer = optimizer_adam(0.001),\n",
        "    metrics = \"r2_score\")\n",
        "\n",
        "summary(model_rn4)"
      ],
      "metadata": {
        "id": "ryIQkA2Fh4Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history4 <- model_rn4 %>% fit(\n",
        "  x = X_train,\n",
        "  y = Y_train,\n",
        "  validation_split = 0.2,\n",
        "  verbose = 2,\n",
        "  epochs = 50)\n",
        "\n",
        "plot(history4)\n",
        "history4"
      ],
      "metadata": {
        "id": "8ti7272MiD6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dos capas lineales, epochs = 30, loss = mean_squared_error, learning_rate = 0.001"
      ],
      "metadata": {
        "id": "TYW6Fg6XO8FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rn5 <- keras_model_sequential(shape=c(10)) %>%\n",
        "    normalizer() %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(1)\n",
        "\n",
        "model_rn5 %>% compile(\n",
        "    loss = 'mean_squared_error',\n",
        "    optimizer = optimizer_adam(0.001),\n",
        "    metrics = \"r2_score\")\n",
        "\n",
        "summary(model_rn5)"
      ],
      "metadata": {
        "id": "Sdgzan79l6Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history5 <- model_rn5 %>% fit(\n",
        "  x = X_train,\n",
        "  y = Y_train,\n",
        "  validation_split = 0.2,\n",
        "  verbose = 2,\n",
        "  epochs = 30)\n",
        "\n",
        "  plot(history5)\n",
        "  history5"
      ],
      "metadata": {
        "id": "YUBjbs8HmEBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tres capas lineales, loss = mean_squared_error, learning_rate = 0.01, epoch = 30"
      ],
      "metadata": {
        "id": "UEYPFvFcYDZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rn6 <- keras_model_sequential(shape=c(10)) %>%\n",
        "    normalizer() %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(1)\n",
        "\n",
        "model_rn6 %>% compile(\n",
        "    loss = 'mean_squared_error',\n",
        "    optimizer = optimizer_adam(0.01),\n",
        "    metrics = \"r2_score\")\n",
        "\n",
        "summary(model_rn6)"
      ],
      "metadata": {
        "id": "M-CGnFLsXfk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history6 <- model_rn6 %>% fit(\n",
        "  x = X_train,\n",
        "  y = Y_train,\n",
        "  validation_split = 0.2,\n",
        "  verbose = 2,\n",
        "  epochs = 30)\n",
        "\n",
        "  plot(history6)\n",
        "  history6"
      ],
      "metadata": {
        "id": "X2QkYwiiYCOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tres capas lineales, loss = mean_squared_error, learning_rate = 0.001, epoch = 30"
      ],
      "metadata": {
        "id": "lmu1gQrRbA1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rn7 <- keras_model_sequential(shape=c(10)) %>%\n",
        "    normalizer() %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(64, activation = 'relu') %>%\n",
        "    layer_dense(1)\n",
        "\n",
        "model_rn7 %>% compile(\n",
        "    loss = 'mean_squared_error',\n",
        "    optimizer = optimizer_adam(0.001),\n",
        "    c(\"r2_score\", \"mean_absolute_error\")\n",
        "\n",
        "summary(model_rn7)"
      ],
      "metadata": {
        "id": "Q2PQ6efqckog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history7 <- model_rn7 %>% fit(\n",
        "  x = X_train,\n",
        "  y = Y_train,\n",
        "  validation_split = 0.3,\n",
        "  verbose = 2,\n",
        "  epochs = 30)\n",
        "\n",
        "  plot(history7)\n",
        "  history7"
      ],
      "metadata": {
        "id": "0oGR4Nxod67M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}